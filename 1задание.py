# -*- coding: utf-8 -*-
"""1задание.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1G3vUvS7P_8FfskojHHYwhPrhiUC4JRz3
"""

from google.colab import drive
drive.mount('gdrive')

import requests
import urllib.request
from bs4 import BeautifulSoup
import re


def get_albums_urls(band_name):
    url = 'http://www.darklyrics.com/' + band_name[0] + '/' + band_name + '.html'

    # Connect to the URL
    response = requests.get(url)

    soup = BeautifulSoup(response.text, "html.parser")

    # List of urls to album texts
    album_urls = []

    # Get band
    band_url = 'http://www.darklyrics.com'
    
    line_count = 1 #variable to track what line you are on
    i = 0
    for one_a_tag in soup.findAll('a'): 

        if line_count > 30: #code for text files starts at line 30

            link = one_a_tag['href']
            link = link.replace('..', '')
            
            # get rid of unnecessary info
            if link == '' or link[0:7] != '/lyrics': 
                continue
            # get links to song texts
            album_url = band_url + link

            # print(album_url)

            album_urls.append(album_url)

        line_count +=1
        i += 1

    return album_urls


def get_band_texts(band_name):

    album_urls = get_albums_urls(band_name)

    album_texts = []

    for album_url in album_urls:

        if album_url[-2] != '#' or int(album_url[-1]) > 1:
            continue

        local_response = requests.get(album_url)
        local_soup = BeautifulSoup(local_response.text, "html.parser")

        for div in local_soup.find_all("div", {'class':'thanks'}): 
            div.decompose()

        for div in local_soup.find_all("div", {'class':'note'}): 
            div.decompose()

        for div in local_soup.findAll('a'):
            del div['href']

        local_album_text = str(local_soup.find_all("div", {"class": "lyrics"}))

        ind_txt = [(m.start(0), m.end(0)) for m in re.finditer(r'<a name="\d[\d]?">\d[\d]?. ', local_album_text)]

        for i in range(len(ind_txt) - 1):

            # get song text by start index and stop index
            song_text = local_album_text[ind_txt[i][1]:ind_txt[i + 1][0]]
            song_text = clean_text(song_text)

            # words_num += len(song_text.split())
            album_texts.append(song_text + "\n")

            if i == (len(ind_txt) - 2):
                i = len(ind_txt) - 1
                song_text = local_album_text[ind_txt[i][1]:]
                song_text = clean_text(song_text)

                album_texts.append(song_text+ "\n")

    return album_urls, album_texts


def clean_text(_text):
    # delete all elements: <div>, <br> and etc
    text = re.sub(r'<[/]?\w+[/]?[>]', '', _text)
    # delete spaces
    text = re.sub(r'  ', ' ', text)
    text = re.sub(r'[|]|x2', ' ', text)
    # replace \n with <eos>
    text = text.replace("\n", " ")
    # delete . 
    text = text.replace(".", " ")
    # delete first word
    text = re.sub(r'^\W*\w+\w* <eos> ', '', text)
    # delete second word
    text = re.sub(r'\w+ \w+ <eos> ]$', '', text)
    # get rid of double <eos>
    text = re.sub(r'<eos>  ', '', text)
    return text


def get_txt_file(path, album_texts):
    output = path
    f = open(output, 'w')
    f.write(album_texts)
    f.close()  


def get_index_file(path, album_urls):
    output = path
    f = open(output, 'w')

    for i, album_url in enumerate(album_urls):
        f.write(str(i + 1) + ' ' + album_url + '\n')

    f.close()

band = 'archenemy'

res_path = 'gdrive/My Drive/4курс/Инфопоиск/result/'

album_urls = get_band_texts(band)[0]
album_texts = get_band_texts(band)[1]

print(len(album_urls))
print(len(album_texts))

for i, album_text in enumerate(album_texts):
    get_txt_file(res_path + 'выкачка' + str(i + 1) + '.txt', album_text)
  
get_index_file(res_path + 'index.txt', album_urls)